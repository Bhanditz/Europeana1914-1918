##
# Model storing common words from the Sphinx search index.
#
# Used for auto-complete functionality on the collection search form.
#
class SearchIndexWord < ActiveRecord::Base
  # Minimum length of word to index and return as an auto-complete suggestion.
  # Needs to be 1 for phrase searches to work.
#  MIN_PREFIX_LEN = 1
  
  # Only save words of a minimum of this length
  MIN_WORD_LEN = 3
  
  # Maximum number of matches to return
  MAX_MATCHES = 30
  
  validates_presence_of :text
  validates_uniqueness_of :text
  validates_inclusion_of :stop_word, :in => [ true, false ]
  validates_length_of :text, :minimum => MIN_WORD_LEN
  
  ##
  # Populates the table from a Sphinx stop words file.
  #
  # This method will delete from the database all stop words
  # (flagged by the {#stop_word} attribute), and repopulate with those from
  # the list.
  #
  # This can be triggered from the command-line using the Rake task:
  #   bundle exec rake auto_complete:import
  #
  # The stop words file is a plain text file with one word per line, as
  # generated by the Sphinx `indexer` binary when run with the --buildstops
  # option. A Rake task is provided to generate this file for local Sphinx
  # installations: 
  #   bundle exec rake auto_complete:generate
  #
  # If frequencies are included in the stop words file as the second file,
  # separated by a space, they will be stored to the {#frequency} attribute.
  # Frequencies can be generated in the Sphinx stop words file with the
  # --buildfreqs option.
  #
  # @param [String] path Path to the stop words file
  # @return [Fixnum] Resulting number of stop word records in the database
  #
  #--
  # @todo A single multi-row insert directly into the db would make this much 
  #   faster.
  #++
  #
  def self.from_stop_words_file!(path)
    raise Exception, "Stop words file \"#{path}\" not found" unless File.exists?(path)
    
    self.delete_all(:stop_word => true)
    
    stop_words_and_freqs = File.open(path, "r").collect do |line|
      line.sub!(Regexp.new("#{$/}$"), '') # Remove line separator
      line.split(' ')
    end
    
    stop_words_and_freqs.reject! do |word_and_freq|
      word = word_and_freq.first
      word.length < MIN_WORD_LEN || # Ignore words shorter than the minimum length
      word.match(/^\d+$/) # Ignore numbers
    end
    
    stop_words_and_freqs.each do |word_and_freq|
      word, freq = word_and_freq
      # This will silently fail validation if the word is already in the db.
      self.create(:text => word, :frequency => freq, :stop_word => true) 
    end
    
    self.where(:stop_word => true).count
  end
  
  ##
  # Creates search index word records from collection metadata
  #
  # Contribution-specific metadata fields:
  # * Title
  # * Alternative title
  # * Protagonist names
  # * Contributor name
  # * Contributed on behalf of
  # * Creator name
  # * Subject 
  # * Location name
  #
  # Taxonomy terms:
  # * Keywords
  # * Keywords: Forces
  # * Theatres of War
  # * File type
  #
  def self.from_collection_metadata!
    self.delete_all(:stop_word => false)
    
    # Taxonomy terms
    phrases_and_freqs = [ ]
    
    fields = [ 'keywords', 'theatres', 'forces', 'file_type' ]
    fields.each do |name|
      field = MetadataField.find_by_name(name)
      if field.present?
        field.taxonomy_terms.each do |tt|
          if tt.term.match(/\s/) || self.where(:text => tt.term).first.blank?
            freq = Contribution.select('id').where(:id => tt.metadata_record_ids).size
            phrases_and_freqs << [ tt.term, freq ]
          end
        end
      end
    end
    
    phrases_and_freqs.each do |phrase_and_freq|
      self.create(:text => phrase_and_freq[0], :stop_word => false, :frequency => phrase_and_freq[1]) 
    end
    
    # Contribution-specific metadata
    Contribution.includes(:metadata).where(:current_status => ContributionStatus.published).find_each do |contribution|
      phrases = [ ]
      phrases << contribution.title
      phrases << contribution.metadata.fields['alternative']
      phrases << full_name(contribution.metadata.fields['character1_given_name'], contribution.metadata.fields['character1_family_name'])
      phrases << full_name(contribution.metadata.fields['character2_given_name'], contribution.metadata.fields['character2_family_name'])
      phrases << contribution.contact.full_name
      phrases << contribution.metadata.fields['contributor_behalf']
      phrases << full_name(contribution.metadata.fields['creator_given_name'], contribution.metadata.fields['creator_family_name'])
      phrases << contribution.metadata.fields['subject']
      phrases << contribution.metadata.fields['location_placename']
      
      phrases.reject! { |phrase| phrase.blank? || !phrase.match(/\s/) }
      
      phrases.each do |phrase|
        existing = self.where(:text => phrase).first
        if existing.present?
          if !existing.stop_word
            existing.update_attributes(:frequency => (existing.frequency + 1))
          end
        else
          self.create(:text => phrase, :stop_word => false, :frequency => 1) 
        end
      end
    end
    
    self.where(:stop_word => false).count
  end
  
  ##
  # ThinkingSphinx index block
  #
#  define_index do
#    indexes text
#    has frequency
#    set_property :enable_star => 0
#    set_property :min_prefix_len => MIN_PREFIX_LEN
#    set_property :max_matches => MAX_MATCHES
#  end
  
  protected
  def self.full_name(given, family)
    [ given, family ].reject { |part| part.blank? }.join(' ')
  end
end
